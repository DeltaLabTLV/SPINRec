{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb340bb9-91e3-4f16-97c6-45ea05bd480b",
   "metadata": {},
   "source": [
    "## Note -Running this notebook assuming the explanation dicts are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d13187-d80e-482c-968b-a940a37a0fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import ipynb\n",
    "import importlib\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import torch.multiprocessing as mp\n",
    "from openpyxl.cell.cell import MergedCell\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5c034-70a8-401a-92c9-ea21ab6821aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = [\"ML1M\", \"Yahoo\", \"Pinterest\"]\n",
    "recommender_names = [\"MLP\", \"VAE\", \"NCF\"]\n",
    "expl_names = ['cosine', 'accent', 'shap', 'deep_shap', 'lime', 'lire', 'fia', 'lxr', 'PI_base', 'SPINRec']\n",
    "\n",
    "# Create plots directory\n",
    "plots_dir = Path('NAME') #Fill name\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "\n",
    "export_dir = Path(os.getcwd()) \n",
    "checkpoints_path = Path(export_dir.parent, \"check\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743e4a1-35a0-4433-bb93-7864998f0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\",\n",
    "    \"NCF\": \"single\",\n",
    "}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"ML1M_demographic\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155\n",
    "}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"ML1M_demographic\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362\n",
    "}\n",
    "\n",
    "demographic_dict = {\n",
    "    \"ML1M_demographic\": True,\n",
    "    \"ML1M\":False,\n",
    "    \"Yahoo\":False, \n",
    "    \"Pinterest\":False\n",
    "}\n",
    "\n",
    "features_dict = {\n",
    "    \"ML1M_demographic\": 3421,\n",
    "    \"ML1M\":None,\n",
    "    \"Yahoo\":None, \n",
    "    \"Pinterest\":None\n",
    "}\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "\n",
    "    (\"ML1M_demographic\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_demographic_0.0001_64_6_18.pt\"),\n",
    "    (\"ML1M_demographic\",\"MLP\"):Path(checkpoints_path, \"MLP_ML1M_demographic_0.0_64_0_28.pt\"),\n",
    "    (\"ML1M_demographic\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_demographic_0.00023_32_3_2.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_12_18_0.0001_256.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\"),\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\"),    \n",
    "}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "\n",
    "    (\"ML1M_demographic\",\"VAE\"): None,\n",
    "    (\"ML1M_demographic\",\"MLP\"): 32,\n",
    "    (\"ML1M_demographic\",\"NCF\"): 8,\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64,\n",
    "}\n",
    "\n",
    "LXR_checkpoint_dict = {\n",
    "    (\"ML1M\",\"VAE\"): ('LXR_ML1M_VAE_26_38_128_3.185652725834087_1.420642300151426.pt',128),\n",
    "    (\"ML1M\",\"MLP\"): ('LXR_ML1M_MLP_12_39_64_11.59908096547193_0.1414854294885049.pt',64),\n",
    "    (\"ML1M\",\"NCF\"): ('LXR_ML1M_NCF_neg_13_39_64_0_17.45690446559206.pt',64),\n",
    "\n",
    "    (\"ML1M_demographic\",\"VAE\"): ('LXR_ML1M_demographic_VAE_comb_0_28_128_4.336170186907191_1.7621772323665827.pt',128),\n",
    "    (\"ML1M_demographic\",\"MLP\"): ('LXR_ML1M_demographic_MLP_pos_12_17_64_5.146220684658705_0.pt',64),\n",
    "    (\"ML1M_demographic\",\"NCF\"): (\"LXR_ML1M_demographic_NCF_combined_neg-pos_19_34_128_19.620894652874913_7.7059602612458615.pt\",128),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): ('LXR_Yahoo_VAE_neg-1.5pos_combined_19_26_128_18.958765029913238_4.92235962483309.pt',128),\n",
    "    (\"Yahoo\",\"MLP\"):('LXR_Yahoo_MLP_neg-pos_combined_last_29_37_128_12.40692505393434_0.19367009952856118.pt',128),\n",
    "    (\"Yahoo\",\"NCF\"):('LXR_Yahoo_NCF_neg-pos_combined_loss_14_14_32_16.01464392466348_6.880015038643981.pt',32),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): ('LXR_Pinterest_VAE_comb_5_39_32_4.369254579125666_0.9909558815719377.pt',32),\n",
    "    (\"Pinterest\",\"MLP\"):('LXR_Pinterest_MLP_0_5_16_10.059416809308486_0.705778173474644.pt',16),\n",
    "    (\"Pinterest\",\"NCF\"): ('LXR_Pinterest_NCF_comb_12_39_64_2.6246630808370672_0.04433778750788146.pt',64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fda75b-849d-4a71-81b1-e4ed749e3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.baselines_functions import *\n",
    "importlib.reload(ipynb.fs.defs.baselines_functions)\n",
    "from ipynb.fs.defs.baselines_functions import *\n",
    "\n",
    "lime = LimeBase(distance_to_proximity)\n",
    "\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "\n",
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f221f8-c75a-477c-856e-001e8e2bddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_user_metrics(user_vector, user_tensor, item_id, item_tensor, recommender_model, expl_dict, **kw_dict):\n",
    "    \"\"\"Calculate metrics for a single user with 5 steps of item masking \"\"\"\n",
    "\n",
    "    original_user_tensor = user_tensor.clone()\n",
    "    original_score = recommender_run(original_user_tensor,recommender_model,item_tensor,item_id, **kw_dict)\n",
    "    original_score_float = original_score.detach().cpu().numpy() + 1e-9\n",
    "    if original_score_float <= 1e-9:\n",
    "        print(f\"Warning: Original score is close to zero for item {item_id}.DEL/INS might be unstable.\")\n",
    "        original_score_float = 1e-9\n",
    "\n",
    "    # tensor used throughout (target item masked out)\n",
    "    user_tensor_for_expl = user_tensor.clone()\n",
    "    user_tensor_for_expl[item_id] = 0\n",
    "\n",
    "    # --- metric containers ---\n",
    "    num_steps = 5\n",
    "    bins = range(1, num_steps + 1)\n",
    "\n",
    "    POS_at_1   = [0] * num_steps\n",
    "    POS_at_5   = [0] * num_steps\n",
    "    POS_at_10  = [0] * num_steps\n",
    "    POS_at_20  = [0] * num_steps\n",
    "    POS_at_50  = [0] * num_steps\n",
    "    POS_at_100 = [0] * num_steps\n",
    "\n",
    "    DEL = [0.0] * num_steps\n",
    "    INS = [0.0] * num_steps\n",
    "    NDCG = [0.0] * num_steps\n",
    "\n",
    "    # ---- prepare explanation list -----\n",
    "    # Get sorted items by importance\n",
    "    # Assuming expl_dict is a list of (item_id, score) tuples from the explanation method\n",
    "    \n",
    "    if not isinstance(expl_dict, list):\n",
    "        try:\n",
    "             # If it has items method (dict-like), convert; else try casting to list\n",
    "            sim_items_list = (list(expl_dict.items())\n",
    "                              if hasattr(expl_dict, 'items')\n",
    "                              else list(expl_dict))\n",
    "        except Exception as e:\n",
    "             # Return empty/default metrics or raise error\n",
    "            print(f\"Error converting expl_dict to list: {e}\")\n",
    "            empty_res = [np.zeros(num_steps)] * 9\n",
    "            return empty_res\n",
    "    else:\n",
    "        sim_items_list = list(expl_dict)\n",
    "\n",
    "    try:\n",
    "        # Sort by score (descending for POS, ascending for NEG)\n",
    "        # Handle potential errors if items in list are not tuples or don't have score at index 1\n",
    "        valid_items = [it for it in sim_items_list\n",
    "                       if isinstance(it, (list, tuple)) and len(it) >= 2]\n",
    "        if len(valid_items) != len(sim_items_list):\n",
    "            print(\"Warning: Some items in expl_dict are invalid; filtered out.\")\n",
    "        POS_sim_items = sorted(valid_items, key=lambda it: it[1], reverse=True)\n",
    "    except (IndexError, TypeError) as e:\n",
    "        print(f\"Error sorting explanation list: {e}\")\n",
    "        empty_res = [np.zeros(num_steps)] * 9\n",
    "        return empty_res\n",
    "\n",
    "    # For each step (1 to 5 items)\n",
    "    for i, k in enumerate(bins):\n",
    "        # Masks for top-k important items (most important)\n",
    "        POS_mask_tensor = torch.zeros_like(user_tensor_for_expl,\n",
    "                                           dtype=torch.float32,\n",
    "                                           device=kw_dict['device'])\n",
    "        k_pos = min(k, len(POS_sim_items))\n",
    "        if k_pos > 0:\n",
    "            # Check if POS_sim_items is empty before slicing/list comprehension\n",
    "            top_k_pos_indices = [p[0] for p in POS_sim_items[:k_pos]]\n",
    "            if top_k_pos_indices:\n",
    "                POS_mask_tensor[top_k_pos_indices] = 1\n",
    "\n",
    "        # tensors for metrics\n",
    "        DEL_tensor = user_tensor_for_expl * (1 - POS_mask_tensor)\n",
    "        INS_tensor = user_tensor_for_expl * POS_mask_tensor\n",
    "        POS_ranking_tensor = DEL_tensor\n",
    "\n",
    "        # ranked list after deleting top-k\n",
    "        POS_ranked_list = get_top_k(POS_ranking_tensor,\n",
    "                                    user_tensor_for_expl,\n",
    "                                    recommender_model, **kw_dict)\n",
    "        ranked_keys = list(POS_ranked_list.keys())\n",
    "        POS_index = (ranked_keys.index(item_id) + 1\n",
    "                     if item_id in ranked_keys\n",
    "                     else kw_dict['num_items'])\n",
    "\n",
    "        # ---- P@K -----\n",
    "        POS_at_1[i]   = 1 if POS_index <= 1   else 0\n",
    "        POS_at_5[i]   = 1 if POS_index <= 5   else 0\n",
    "        POS_at_10[i]  = 1 if POS_index <= 10  else 0\n",
    "        POS_at_20[i]  = 1 if POS_index <= 20  else 0\n",
    "        POS_at_50[i]  = 1 if POS_index <= 50  else 0\n",
    "        POS_at_100[i] = 1 if POS_index <= 100 else 0\n",
    "\n",
    "        # --- DEL ---\n",
    "        score_del = recommender_run(DEL_tensor, recommender_model,\n",
    "                                    item_tensor, item_id, **kw_dict)\n",
    "        if np.isnan(original_score_float) or original_score_float == 0:\n",
    "            DEL[i] = np.nan\n",
    "        else:\n",
    "            DEL[i] = float(score_del.detach().cpu().numpy()\n",
    "                           / original_score_float)\n",
    "\n",
    "        # --- INS  ---\n",
    "        score_ins = recommender_run(INS_tensor, recommender_model, item_tensor, item_id, **kw_dict)\n",
    "        if np.isnan(original_score_float) or original_score_float == 0:\n",
    "            INS[i] = np.nan\n",
    "        else:\n",
    "            INS[i] = float(score_ins.detach().cpu().numpy()\n",
    "                           / original_score_float)\n",
    "        # ---- NDCG ----------------------------------------------------------\n",
    "        NDCG[i] = get_ndcg(ranked_keys, item_id, **kw_dict)\n",
    "\n",
    "    # ---- return -----------------------------------------------------------\n",
    "    return [np.array(DEL),\n",
    "            np.array(INS),\n",
    "            np.array(NDCG),\n",
    "            np.array(POS_at_1),\n",
    "            np.array(POS_at_5),\n",
    "            np.array(POS_at_10),\n",
    "            np.array(POS_at_20),\n",
    "            np.array(POS_at_50),\n",
    "            np.array(POS_at_100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29926883-2c7f-4130-9e39-e88baec17045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_expl_type(expl_name):\n",
    "    print(f' ============ Start explaining {data_name} {recommender_name} by {expl_name} ============')\n",
    "\n",
    "    num_steps = 5\n",
    "    users_DEL  = np.zeros(num_steps)\n",
    "    users_INS  = np.zeros(num_steps)\n",
    "    NDCG       = np.zeros(num_steps)\n",
    "\n",
    "    POS_at_1   = np.zeros(num_steps)\n",
    "    POS_at_5   = np.zeros(num_steps)\n",
    "    POS_at_10  = np.zeros(num_steps)\n",
    "    POS_at_20  = np.zeros(num_steps)\n",
    "    POS_at_50  = np.zeros(num_steps)\n",
    "    POS_at_100 = np.zeros(num_steps)\n",
    "\n",
    "    # Load explanation dicts\n",
    "    if expl_name == 'SPINRec':\n",
    "        spinrec_dir = Path(os.getcwd()).parent / \"processed_data\" / data_name / \"PI\" / recommender_name / \"sample_random_user\"\n",
    "    else:\n",
    "        with open(Path(files_path, f'{recommender_name}_{expl_name}_expl_dict.pkl'), 'rb') as handle:\n",
    "            expl_dict = pickle.load(handle)\n",
    "\n",
    "    recommender.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(test_array.shape[0])):\n",
    "        # for i in tqdm(range(3)):\n",
    "            user_vector = test_array[i].copy()\n",
    "            user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "            user_id = int(test_data.index[i])\n",
    "\n",
    "            item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "            item_vector = items_array[item_id]\n",
    "            item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "\n",
    "            user_vector[item_id] = 0\n",
    "            user_tensor[item_id] = 0\n",
    "\n",
    "            # --- SPINRec custom logic ---\n",
    "            if expl_name == 'SPINRec':\n",
    "                best_res = None\n",
    "                for k in range(1, 12):\n",
    "                    folder_path = spinrec_dir / str(k)\n",
    "                    pkl_path = folder_path / f'PI_expl_dict_user_{i}.pkl'\n",
    "\n",
    "                    if not pkl_path.exists():\n",
    "                        print(f\"Missing file: {pkl_path}\")\n",
    "                        continue\n",
    "\n",
    "                    with open(pkl_path, 'rb') as f:\n",
    "                        candidate_expl_dict = pickle.load(f)\n",
    "\n",
    "                    user_expl = candidate_expl_dict.get(user_id)\n",
    "                    if user_expl is None:\n",
    "                        print(f\"User {user_id} not found in {pkl_path}\")\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        res = single_user_metrics(user_vector.copy(), user_tensor.clone(), item_id, item_tensor, recommender, user_expl, **kw_dict)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error evaluating metrics for user {user_id} in trial {k}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    if best_res is None:\n",
    "                        best_res = res\n",
    "                    else:\n",
    "                        # Choose best result: max INS, min everything else\n",
    "                        best_res = [\n",
    "                            np.maximum(best_res[j], res[j]) if j == 1 else np.minimum(best_res[j], res[j]) ## j ==1 is the location of INS!!!\n",
    "                            for j in range(len(res))\n",
    "                        ]\n",
    "\n",
    "                if best_res is None:\n",
    "                    print(f\"Warning: No valid explanations found for user {user_id} in SPINRec.\")\n",
    "                    continue\n",
    "\n",
    "                res = best_res\n",
    "            else:\n",
    "                # Default explainer logic\n",
    "                user_expl = expl_dict.get(user_id)\n",
    "                if user_expl is None:\n",
    "                    print(f\"User {user_id} not found in {expl_name} expl_dict.\")\n",
    "                    continue\n",
    "                res = single_user_metrics(user_vector, user_tensor, item_id, item_tensor, recommender, user_expl, **kw_dict)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            users_DEL  += res[0]   # DEL\n",
    "            users_INS  += res[1]   # INS\n",
    "            NDCG       += res[2]   # NDCG\n",
    "\n",
    "            POS_at_1   += res[3]   # POS@1\n",
    "            POS_at_5   += res[4]   # POS@5\n",
    "            POS_at_10  += res[5]   # POS@10\n",
    "            POS_at_20  += res[6]   # POS@20\n",
    "            POS_at_50  += res[7]   # POS@50\n",
    "            POS_at_100 += res[8]   # POS@100\n",
    "\n",
    "    a = test_array.shape[0]\n",
    "    \n",
    "    return {\n",
    "        'DEL':       users_DEL  / a,\n",
    "        'INS':       users_INS  / a,\n",
    "        'NDCG':      NDCG       / a,\n",
    "        'POS_at_1':  POS_at_1   / a,\n",
    "        'POS_at_5':  POS_at_5   / a,\n",
    "        'POS_at_10': POS_at_10  / a,\n",
    "        'POS_at_20': POS_at_20  / a,\n",
    "        'POS_at_50': POS_at_50  / a,\n",
    "        'POS_at_100': POS_at_100 / a\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fcdd0a-259c-411b-bc56-ac0c6e10dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_metrics(results, data_name, recommender_name):\n",
    "    # Mapping of metrics to their display properties\n",
    "    # Assuming 5 steps, the x-axis label for INS should be different\n",
    "    metrics_mapping = {\n",
    "        'DEL':        ('DEL@Ke',     \"Number of Masked Items\"),\n",
    "        'INS':        ('INS@Ke',     \"Number of Items Added\"),\n",
    "        'NDCG':       ('CDCG@Ke',    \"Number of Masked Items\"),\n",
    "\n",
    "        'POS_at_1':   ('POS@1,Ke',   \"Number of Masked Items\"),\n",
    "        'POS_at_5':   ('POS@5,Ke',   \"Number of Masked Items\"),\n",
    "        'POS_at_10':  ('POS@10,Ke',  \"Number of Masked Items\"),\n",
    "        'POS_at_20':  ('POS@20,Ke',  \"Number of Masked Items\"),\n",
    "        'POS_at_50':  ('POS@50,Ke',  \"Number of Masked Items\"),\n",
    "        'POS_at_100': ('POS@100,Ke', \"Number of Masked Items\"),\n",
    "    }\n",
    "\n",
    "    # Styling\n",
    "    colors = [\n",
    "    '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
    "    '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "    '#bcbd22', '#17becf', '#393b79', '#8c6d31'\n",
    "    ]\n",
    "    markers = ['o', 's', '^', 'D', 'v', 'x', '*', 'P', 'H', '<', '>', 'X']\n",
    "    linestyles = [\n",
    "        '-', '--', '-.', ':', (0, (3, 1, 1, 1)), (0, (5, 2)),\n",
    "        (0, (1, 1)), (0, (5, 1)), (0, (3, 5, 1, 5)), (0, (3, 1, 1, 1, 1, 1)),\n",
    "        (0, (4, 4)), (0, (2, 2))\n",
    "    ]\n",
    "\n",
    "    # Plot each metric\n",
    "    for metric_name, (y_label, x_label) in metrics_mapping.items():\n",
    "        plt.figure(figsize=(14, 10))\n",
    "\n",
    "        # Plot each baseline\n",
    "        legend_labels = []\n",
    "        valid_baseline_found = False # Flag to check if any baseline has the metric\n",
    "        \n",
    "        for i, (baseline, baseline_metrics) in enumerate(results.items()):\n",
    "            if baseline==\"PI_base\":\n",
    "                baseline=\"ABLT\"\n",
    "            if metric_name not in baseline_metrics:\n",
    "                print(f\"Warning: {metric_name} not found in {baseline} metrics\") # Optional warning\n",
    "                continue\n",
    "\n",
    "            valid_baseline_found = True # Mark that we found data for this metric\n",
    "            values = baseline_metrics[metric_name]\n",
    "\n",
    "            # Ensure values is a numpy array for plotting\n",
    "            if not isinstance(values, np.ndarray):\n",
    "                try:\n",
    "                    values = np.array(values)\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not convert values for {metric_name} in {baseline} to numpy array: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Ensure values is not empty and is 1D\n",
    "            if values.size == 0 or values.ndim != 1:\n",
    "                 print(f\"Warning: Invalid data shape for {metric_name} in {baseline}. Shape: {values.shape}. Skipping plot.\")\n",
    "                 continue\n",
    "\n",
    "            # Generate x-coordinates (assuming 5 steps, so 5 points)\n",
    "            # If your results have a different number of steps, adjust this\n",
    "            num_steps = len(values)\n",
    "            if num_steps != 5:\n",
    "                 print(f\"Warning: Expected 5 steps for {metric_name} in {baseline}, found {num_steps}. Adjusting x-axis.\")\n",
    "            # x = np.linspace(0, 1, num_steps) # If x-axis should be percentage 0 to 1\n",
    "            x = np.arange(1, num_steps + 1) # If x-axis should be step number 1 to 5\n",
    "\n",
    "            plt.plot(\n",
    "                x, values,\n",
    "                color=colors[i % len(colors)],\n",
    "                linestyle=linestyles[i % len(linestyles)],\n",
    "                marker=markers[i % len(markers)],\n",
    "                markersize=8,\n",
    "                linewidth=2,\n",
    "                label=baseline.upper()\n",
    "            )\n",
    "            legend_labels.append(baseline.upper())\n",
    "\n",
    "        # Only proceed if we found data for this metric\n",
    "        if not valid_baseline_found:\n",
    "            print(f\"Skipping plot for {metric_name} as no valid data was found in any baseline.\")\n",
    "            plt.close() # Close the empty figure\n",
    "            continue\n",
    "\n",
    "        # Use the specific x_label from the mapping\n",
    "        plt.xlabel(x_label, fontsize=30)\n",
    "        plt.ylabel(y_label, fontsize=30)\n",
    "        plt.title(f\"{data_name}  |  {recommender_name}  |  {y_label}\", fontsize=32, pad=20)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7, linewidth=0.5)\n",
    "        plt.xticks(np.arange(1, num_steps + 1), fontsize=18) # Set ticks explicitly for steps 1-5\n",
    "        plt.yticks(fontsize=18)\n",
    "\n",
    "        # Add legend if we have labels\n",
    "        if legend_labels:\n",
    "            print(metric_name)\n",
    "            if metric_name=='INS':\n",
    "                plt.legend(fontsize=14, loc='upper left', frameon=True)\n",
    "            else:\n",
    "                plt.legend(fontsize=14, loc='lower left', frameon=True)\n",
    "        \n",
    "        # Save plot\n",
    "        safe_name = metric_name.replace('@', 'at').replace(',', '_')\n",
    "        plot_path = plots_dir / f'{data_name}_{recommender_name}_{safe_name}_d.pdf'\n",
    "        plt.savefig(plot_path, format='pdf', bbox_inches='tight', dpi=1000)\n",
    "        print(f\"Saved plot: {plot_path.name}\") # Print just the filename\n",
    "        plt.close() # Close the figure to free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6720ac-2d4b-49be-a658-b2936465b3b7",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11be6e8-ba23-4189-a90b-219e9f634b73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize storage for all results\n",
    "all_results = {}\n",
    "\n",
    "workspace_root = export_dir.parent\n",
    "\n",
    "for data_name in data_names:\n",
    "    DP_DIR = Path(\"processed_data\", data_name)\n",
    "    files_path = Path(workspace_root, DP_DIR)\n",
    "    checkpoints_path = Path(workspace_root, \"check\")\n",
    "\n",
    "    # Load dataset-specific parameters and data\n",
    "    num_users = num_users_dict[data_name] \n",
    "    num_items = num_items_dict[data_name] \n",
    "    demographic = demographic_dict[data_name]\n",
    "    if demographic:\n",
    "        num_features = features_dict[data_name]\n",
    "    else:\n",
    "        num_features = num_items_dict[data_name]\n",
    "\n",
    "    # Use the correctly defined files_path\n",
    "    with open(Path(files_path, f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "        pop_dict = pickle.load(f)\n",
    "    pop_array = np.zeros(len(pop_dict))\n",
    "    for key, value in pop_dict.items():\n",
    "        pop_array[key] = value\n",
    "\n",
    "    # Load data files using the correct files_path\n",
    "    train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "    test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "    static_test_data = pd.read_csv(Path(files_path,f'static_test_data_{data_name}.csv'), index_col=0)\n",
    "\n",
    "    train_array = train_data.to_numpy()\n",
    "    test_array = test_data.to_numpy() # Use the loaded test_data\n",
    "    items_array = np.eye(num_items)\n",
    "    all_items_tensor = torch.Tensor(items_array).to(device)\n",
    "\n",
    "    for recommender_name in recommender_names:\n",
    "        print(f\"\\nProcessing {data_name} dataset with {recommender_name} recommender\")\n",
    "\n",
    "        # Set up recommender-specific parameters\n",
    "        output_type = output_type_dict[recommender_name]\n",
    "        hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "        recommender_path = recommender_path_dict[(data_name,recommender_name)]\n",
    "\n",
    "\n",
    "        # Make sure kw_dict uses the correct paths and variables defined in this scope\n",
    "        kw_dict = {'device':device,\n",
    "                  'num_items': num_items,\n",
    "                  'demographic':demographic,\n",
    "                  'num_features':num_features,\n",
    "                  'pop_array':pop_array,\n",
    "                  'all_items_tensor':all_items_tensor,\n",
    "                  'static_test_data':static_test_data,\n",
    "                  'items_array':items_array,\n",
    "                  'output_type':output_type,\n",
    "                  'recommender_name':recommender_name}\n",
    "\n",
    "        # Ensure load_recommender uses the correct path\n",
    "        recommender = load_recommender(data_name, hidden_dim, checkpoints_path, recommender_path, **kw_dict)\n",
    "\n",
    "        # Process each explanation method\n",
    "        results = {}\n",
    "        for expl_name in expl_names:\n",
    "            try:\n",
    "                # If it uses global variables, make sure they are correctly set\n",
    "                current_results = eval_one_expl_type(expl_name) # Pass kw_dict if needed: eval_one_expl_type(expl_name, kw_dict=kw_dict)\n",
    "                # Take only first 5 values from each metric array\n",
    "                results[expl_name] = {\n",
    "                    metric: values[:5] if isinstance(values, np.ndarray) and len(values) >= 5 else values\n",
    "                    for metric, values in current_results.items()\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {expl_name} for {data_name} {recommender_name}: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc() # Print full traceback for debugging\n",
    "                continue\n",
    "\n",
    "        # Store results in the overall dictionary\n",
    "        all_results[(data_name, recommender_name)] = results\n",
    "\n",
    "        # Generate and save plots\n",
    "        #### DONT FORGET THE PI RESULTS ALSO NEED TO COME HERE!!!\n",
    "        if results: # Only plot if there are results \n",
    "             plot_all_metrics(results, data_name, recommender_name)\n",
    "        else:\n",
    "            print(f\"Skipping plots for {data_name} {recommender_name} due to processing errors.\")\n",
    "\n",
    "print(\"\\nProcessing complete. Results and visualizations have been saved to plots_discrete directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d2c44-fbba-4a23-a9a1-a81fa3354ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the file path\n",
    "save_path = plots_dir / f'all_results_{data_names}_{recommender_names}.pkl'\n",
    "\n",
    "# Save the dictionary\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "print(f\"Saved all_results to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451467c-5d20-4511-a1d6-377a4e550e39",
   "metadata": {},
   "source": [
    "# Save to XLSX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9d274-29ce-4d9e-a8fd-6de1994fc594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- helpers ------------------------------------------------\n",
    "def to_fixed_len(seq, length=5):\n",
    "    \"\"\"Return a NumPy array of exactly `length` (pad with NaN if needed).\"\"\"\n",
    "    if isinstance(seq, (list, np.ndarray)):\n",
    "        arr = np.asarray(seq).flatten()\n",
    "        if len(arr) < length:\n",
    "            arr = np.concatenate([arr, np.full(length - len(arr), np.nan)])\n",
    "        return arr[:length]\n",
    "    return np.asarray([seq] + [np.nan] * (length - 1))\n",
    "\n",
    "def safe_sheet_name(name: str) -> str:\n",
    "    \"\"\"Sanitise sheet names for Excel (max 31 chars, no : \\ / ? * [ ]).\"\"\"\n",
    "    name = re.sub(r'[:\\\\/?*\\[\\]]', '-', name)   # illegal chars → hyphen\n",
    "    return name[:31]\n",
    "\n",
    "# ----------------------------------------------------------------------------- \n",
    "# `all_results` is assumed to be filled already.\n",
    "# structure: { (data_name, recommender_name): { expl_name: {metric: array/scalar}} }\n",
    "\n",
    "out_dir = Path(\"discrete_metric_xlsx\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "datasets = {key[0] for key in all_results}  # e.g. {\"ML1M\", \"AMZBooks\"}\n",
    "\n",
    "for data_name in datasets:\n",
    "    xlsx_path = out_dir / f\"{data_name}_discrete_metrics.xlsx\"\n",
    "    with pd.ExcelWriter(xlsx_path, engine=\"xlsxwriter\") as writer:\n",
    "\n",
    "        # loop through recommender–metric combinations belonging to this dataset\n",
    "        for (d_name, rec_name), expl_block in all_results.items():\n",
    "            if d_name != data_name:\n",
    "                continue\n",
    "\n",
    "            metrics = next(iter(expl_block.values())).keys()  # take from first expl\n",
    "\n",
    "            for metric in metrics:\n",
    "                # build a tidy DataFrame for this block\n",
    "                rows = []\n",
    "                for expl_name, metric_dict in expl_block.items():\n",
    "                    vals = to_fixed_len(metric_dict[metric])\n",
    "                    rows.append([expl_name, *vals])\n",
    "\n",
    "                df = pd.DataFrame(\n",
    "                    rows,\n",
    "                    columns=[\"Explanation\"] + [f\"val_{i+1}\" for i in range(5)],\n",
    "                )\n",
    "\n",
    "                sheet_name = safe_sheet_name(f\"{rec_name}_{metric}\")\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"✔  Written {xlsx_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
